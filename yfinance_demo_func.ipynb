{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (8, 7)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (roc_auc_score\n",
    "                             , precision_score\n",
    "                             , recall_score\n",
    "                             , roc_curve\n",
    "                             , confusion_matrix\n",
    "                             , plot_confusion_matrix\n",
    "                             , precision_recall_curve\n",
    "                             , auc\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = '60m' # 60m or 1d\n",
    "history = '2y' # 2y for 60m, max for 1d\n",
    "perc_inc = 0.01 # 0.008 for 60m, 0.02 for 1d (IYW)\n",
    "symbol = 'JEF'\n",
    "perc_train = 0.25\n",
    "load_new = 1 # 0 for reuse, 1 for load new from server\n",
    "current = 0 # 0 for 2nd to last data point (once markets open), 1 for last data point (when market is closed)\n",
    "loc = -2 # row for previous nth interval, -2 (once market open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if interval == '1d' or interval == '1wk':\n",
    "    index_col = 'Date'\n",
    "else:\n",
    "    index_col = 'Datetime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-30 09:30:00-04:00</th>\n",
       "      <td>23.146067</td>\n",
       "      <td>23.398876</td>\n",
       "      <td>23.071161</td>\n",
       "      <td>23.136703</td>\n",
       "      <td>23.136703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 10:30:00-04:00</th>\n",
       "      <td>23.127340</td>\n",
       "      <td>23.146067</td>\n",
       "      <td>23.005617</td>\n",
       "      <td>23.108614</td>\n",
       "      <td>23.108614</td>\n",
       "      <td>214816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 11:30:00-04:00</th>\n",
       "      <td>23.117977</td>\n",
       "      <td>23.164795</td>\n",
       "      <td>22.996254</td>\n",
       "      <td>23.000937</td>\n",
       "      <td>23.000937</td>\n",
       "      <td>276253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 12:30:00-04:00</th>\n",
       "      <td>23.000937</td>\n",
       "      <td>23.174158</td>\n",
       "      <td>23.000937</td>\n",
       "      <td>23.172752</td>\n",
       "      <td>23.172752</td>\n",
       "      <td>174425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 13:30:00-04:00</th>\n",
       "      <td>23.174158</td>\n",
       "      <td>23.220974</td>\n",
       "      <td>23.136703</td>\n",
       "      <td>23.183521</td>\n",
       "      <td>23.183521</td>\n",
       "      <td>226602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 14:30:00-04:00</th>\n",
       "      <td>23.183521</td>\n",
       "      <td>23.230337</td>\n",
       "      <td>23.089888</td>\n",
       "      <td>23.089888</td>\n",
       "      <td>23.089888</td>\n",
       "      <td>272941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30 15:30:00-04:00</th>\n",
       "      <td>23.071161</td>\n",
       "      <td>23.108614</td>\n",
       "      <td>23.071161</td>\n",
       "      <td>23.080524</td>\n",
       "      <td>23.080524</td>\n",
       "      <td>393077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 09:30:00-04:00</th>\n",
       "      <td>23.174158</td>\n",
       "      <td>23.174158</td>\n",
       "      <td>22.677902</td>\n",
       "      <td>22.724720</td>\n",
       "      <td>22.724720</td>\n",
       "      <td>329130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 10:30:00-04:00</th>\n",
       "      <td>22.734083</td>\n",
       "      <td>22.752810</td>\n",
       "      <td>22.612360</td>\n",
       "      <td>22.734083</td>\n",
       "      <td>22.734083</td>\n",
       "      <td>215351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 11:30:00-04:00</th>\n",
       "      <td>22.738764</td>\n",
       "      <td>22.874533</td>\n",
       "      <td>22.738764</td>\n",
       "      <td>22.832397</td>\n",
       "      <td>22.832397</td>\n",
       "      <td>155931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 12:30:00-04:00</th>\n",
       "      <td>22.832397</td>\n",
       "      <td>22.869850</td>\n",
       "      <td>22.818352</td>\n",
       "      <td>22.855804</td>\n",
       "      <td>22.855804</td>\n",
       "      <td>140436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 13:30:00-04:00</th>\n",
       "      <td>22.865168</td>\n",
       "      <td>22.902716</td>\n",
       "      <td>22.799625</td>\n",
       "      <td>22.827715</td>\n",
       "      <td>22.827715</td>\n",
       "      <td>154745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 14:30:00-04:00</th>\n",
       "      <td>22.832397</td>\n",
       "      <td>22.832397</td>\n",
       "      <td>22.790262</td>\n",
       "      <td>22.832397</td>\n",
       "      <td>22.832397</td>\n",
       "      <td>136805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31 15:30:00-04:00</th>\n",
       "      <td>22.827715</td>\n",
       "      <td>22.827715</td>\n",
       "      <td>22.705992</td>\n",
       "      <td>22.705992</td>\n",
       "      <td>22.705992</td>\n",
       "      <td>418027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 09:30:00-04:00</th>\n",
       "      <td>22.668539</td>\n",
       "      <td>22.808989</td>\n",
       "      <td>22.631086</td>\n",
       "      <td>22.766853</td>\n",
       "      <td>22.766853</td>\n",
       "      <td>198302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 10:30:00-04:00</th>\n",
       "      <td>22.762173</td>\n",
       "      <td>22.771536</td>\n",
       "      <td>22.584270</td>\n",
       "      <td>22.588951</td>\n",
       "      <td>22.588951</td>\n",
       "      <td>158125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 11:30:00-04:00</th>\n",
       "      <td>22.574907</td>\n",
       "      <td>22.574907</td>\n",
       "      <td>22.415730</td>\n",
       "      <td>22.434458</td>\n",
       "      <td>22.434458</td>\n",
       "      <td>225660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 12:30:00-04:00</th>\n",
       "      <td>22.415730</td>\n",
       "      <td>22.518726</td>\n",
       "      <td>22.406366</td>\n",
       "      <td>22.490637</td>\n",
       "      <td>22.490637</td>\n",
       "      <td>124826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 13:30:00-04:00</th>\n",
       "      <td>22.500000</td>\n",
       "      <td>22.537453</td>\n",
       "      <td>22.368914</td>\n",
       "      <td>22.387640</td>\n",
       "      <td>22.387640</td>\n",
       "      <td>186760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01 14:30:00-04:00</th>\n",
       "      <td>22.387640</td>\n",
       "      <td>22.504683</td>\n",
       "      <td>22.378277</td>\n",
       "      <td>22.443821</td>\n",
       "      <td>22.443821</td>\n",
       "      <td>283587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High        Low      Close  \\\n",
       "Datetime                                                                \n",
       "2018-07-30 09:30:00-04:00  23.146067  23.398876  23.071161  23.136703   \n",
       "2018-07-30 10:30:00-04:00  23.127340  23.146067  23.005617  23.108614   \n",
       "2018-07-30 11:30:00-04:00  23.117977  23.164795  22.996254  23.000937   \n",
       "2018-07-30 12:30:00-04:00  23.000937  23.174158  23.000937  23.172752   \n",
       "2018-07-30 13:30:00-04:00  23.174158  23.220974  23.136703  23.183521   \n",
       "2018-07-30 14:30:00-04:00  23.183521  23.230337  23.089888  23.089888   \n",
       "2018-07-30 15:30:00-04:00  23.071161  23.108614  23.071161  23.080524   \n",
       "2018-07-31 09:30:00-04:00  23.174158  23.174158  22.677902  22.724720   \n",
       "2018-07-31 10:30:00-04:00  22.734083  22.752810  22.612360  22.734083   \n",
       "2018-07-31 11:30:00-04:00  22.738764  22.874533  22.738764  22.832397   \n",
       "2018-07-31 12:30:00-04:00  22.832397  22.869850  22.818352  22.855804   \n",
       "2018-07-31 13:30:00-04:00  22.865168  22.902716  22.799625  22.827715   \n",
       "2018-07-31 14:30:00-04:00  22.832397  22.832397  22.790262  22.832397   \n",
       "2018-07-31 15:30:00-04:00  22.827715  22.827715  22.705992  22.705992   \n",
       "2018-08-01 09:30:00-04:00  22.668539  22.808989  22.631086  22.766853   \n",
       "2018-08-01 10:30:00-04:00  22.762173  22.771536  22.584270  22.588951   \n",
       "2018-08-01 11:30:00-04:00  22.574907  22.574907  22.415730  22.434458   \n",
       "2018-08-01 12:30:00-04:00  22.415730  22.518726  22.406366  22.490637   \n",
       "2018-08-01 13:30:00-04:00  22.500000  22.537453  22.368914  22.387640   \n",
       "2018-08-01 14:30:00-04:00  22.387640  22.504683  22.378277  22.443821   \n",
       "\n",
       "                           Adj Close  Volume  \n",
       "Datetime                                      \n",
       "2018-07-30 09:30:00-04:00  23.136703       0  \n",
       "2018-07-30 10:30:00-04:00  23.108614  214816  \n",
       "2018-07-30 11:30:00-04:00  23.000937  276253  \n",
       "2018-07-30 12:30:00-04:00  23.172752  174425  \n",
       "2018-07-30 13:30:00-04:00  23.183521  226602  \n",
       "2018-07-30 14:30:00-04:00  23.089888  272941  \n",
       "2018-07-30 15:30:00-04:00  23.080524  393077  \n",
       "2018-07-31 09:30:00-04:00  22.724720  329130  \n",
       "2018-07-31 10:30:00-04:00  22.734083  215351  \n",
       "2018-07-31 11:30:00-04:00  22.832397  155931  \n",
       "2018-07-31 12:30:00-04:00  22.855804  140436  \n",
       "2018-07-31 13:30:00-04:00  22.827715  154745  \n",
       "2018-07-31 14:30:00-04:00  22.832397  136805  \n",
       "2018-07-31 15:30:00-04:00  22.705992  418027  \n",
       "2018-08-01 09:30:00-04:00  22.766853  198302  \n",
       "2018-08-01 10:30:00-04:00  22.588951  158125  \n",
       "2018-08-01 11:30:00-04:00  22.434458  225660  \n",
       "2018-08-01 12:30:00-04:00  22.490637  124826  \n",
       "2018-08-01 13:30:00-04:00  22.387640  186760  \n",
       "2018-08-01 14:30:00-04:00  22.443821  283587  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_df = yf.download(tickers = symbol # symbol of stock \n",
    "\n",
    "                           , period = history # length of history back in time\n",
    "\n",
    "                           , interval = interval # time periods of subinterval e.g. 1m or 1hr\n",
    "\n",
    "                           # , start = start # start date, time\n",
    "\n",
    "                           # , end = end # end date, time\n",
    "\n",
    "                           , prepost = False # pre/post market data\n",
    "                          )\n",
    "stock_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction(interval = interval\n",
    "              , history = history\n",
    "              , perc_inc = perc_inc\n",
    "              , symbol = symbol\n",
    "              , perc_train = perc_train\n",
    "              , load_new = load_new \n",
    "              , current = current\n",
    "              , loc = loc\n",
    "             ):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams['font.size'] = 12\n",
    "    plt.rcParams['figure.figsize'] = (8, 7)\n",
    "    plt.style.use('fivethirtyeight')\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    import yfinance as yf\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.metrics import (roc_auc_score\n",
    "                                 , precision_score\n",
    "                                 , recall_score\n",
    "                                 , roc_curve\n",
    "                                 , confusion_matrix\n",
    "                                 , plot_confusion_matrix\n",
    "                                 , precision_recall_curve\n",
    "                                 , auc\n",
    "                                )\n",
    "    \n",
    "    # Load New From Server\n",
    "    if load_new == 1:\n",
    "        stock_df = yf.download(tickers = symbol # symbol of stock \n",
    "\n",
    "                           , period = history # length of history back in time\n",
    "\n",
    "                           , interval = interval # time periods of subinterval e.g. 1m or 1hr\n",
    "\n",
    "                           # , start = start # start date, time\n",
    "\n",
    "                           # , end = end # end date, time\n",
    "\n",
    "                           , prepost = False # pre/post market data\n",
    "                          )\n",
    "        # Create Percent Change\n",
    "        stock_df['percent change'] = (stock_df.Close - stock_df.Open) / stock_df.Open\n",
    "\n",
    "        #create decision column\n",
    "        stock_df['decision'] = np.where((stock_df['Close'] - stock_df['Open'])/stock_df['Open'] > perc_inc\n",
    "\n",
    "                                        , 1  # 1 if up % or greater\n",
    "\n",
    "                                        , 0  # 0 if not up % or greater\n",
    "\n",
    "                                       )\n",
    "        # create one offs\n",
    "        decisions = stock_df.decision.values\n",
    "        decisions = decisions[1:len(decisions)]\n",
    "        stock_df_one_off = stock_df.iloc[0:stock_df.shape[0]-1]\n",
    "        stock_df_one_off['decision'] = decisions\n",
    "\n",
    "        # Save DF to CSV\n",
    "        stock_df.to_csv('stock_df.csv')\n",
    "        \n",
    "    else:\n",
    "        if interval == '1d' or interval == '1wk':\n",
    "            index_col = 'Date'\n",
    "        else:\n",
    "            index_col = 'Datetime'\n",
    "   \n",
    "        stock_df = pd.read_csv('stock_df.csv', index_col=index_col)\n",
    "    \n",
    "        # create one offs\n",
    "        decisions = stock_df.decision.values\n",
    "        decisions = decisions[1:len(decisions)]\n",
    "        stock_df_one_off = stock_df.iloc[0:stock_df.shape[0]-1]\n",
    "        stock_df_one_off['decision'] = decisions\n",
    " \n",
    "    # balance the data\n",
    "    ones = stock_df_one_off.decision.value_counts()[1]\n",
    "    stock_df_bal = stock_df_one_off.groupby('decision').apply(lambda x: x.sample(n=ones)).reset_index(drop=True)\n",
    "    \n",
    "    # check for NaN's\n",
    "    stock_df_bal.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    # Train Test Split\n",
    "    X = stock_df_bal.drop(columns=['decision']) # get columns other than decision\n",
    "    y = stock_df_bal['decision'] # get decision column\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                        , y\n",
    "                                                        , test_size=0.20\n",
    "                                                        , random_state = 42\n",
    "                                                       )\n",
    "    # 1d IYW\n",
    "    # {'bootstrap': True,\n",
    "    #  'max_depth': 4,\n",
    "    #  'max_features': 4,\n",
    "    #  'min_samples_leaf': 2,\n",
    "    #  'min_samples_split': 10,\n",
    "    #  'n_estimators': 5}\n",
    "\n",
    "    # 1hr IYW\n",
    "    # {'bootstrap': True,\n",
    "    #  'max_depth': 4,\n",
    "    #  'max_features': 3,\n",
    "    #  'min_samples_leaf': 3,\n",
    "    #  'min_samples_split': 5,\n",
    "    #  'n_estimators': 25}\n",
    "        \n",
    "    # 1d JEF\n",
    "    # {'bootstrap': False,\n",
    "    #  'max_depth': 2,\n",
    "    #  'max_features': 2,\n",
    "    #  'min_samples_leaf': 1,\n",
    "    #  'min_samples_split': 2,\n",
    "    #  'n_estimators': 45}\n",
    "    \n",
    "    # 1hr JEF\n",
    "    #  {'bootstrap': True,\n",
    "    #  'max_depth': 2,\n",
    "    #  'max_features': 6,\n",
    "    #  'min_samples_leaf': 3,\n",
    "    #  'min_samples_split': 5,\n",
    "    #  'n_estimators': 25}\n",
    "\n",
    "    # random forest classifier rfc\n",
    "    if symbol == 'IYW' and interval == '1d':\n",
    "        rfc = RandomForestClassifier(bootstrap = True\n",
    "                                     , max_depth = 4\n",
    "                                     , max_features = 4\n",
    "                                     , min_samples_leaf = 2\n",
    "                                     , min_samples_split = 10\n",
    "                                     , n_estimators = 7 # int(perc_train * len(X_train)) # odd number\n",
    "                                     , random_state = 42\n",
    "                                     , verbose = 0 # no showing backend work\n",
    "                                     , n_jobs = -1 # access all of your processor cores Lenovo P50 i7-6820HQ 2.7GHz\n",
    "                                    )\n",
    "    elif symbol == 'IYW' and interval == '60m':\n",
    "        rfc = RandomForestClassifier(bootstrap = True\n",
    "                                     , max_depth = 4\n",
    "                                     , max_features = 3\n",
    "                                     , min_samples_leaf = 3\n",
    "                                     , min_samples_split = 5\n",
    "                                     , n_estimators = 25 # int(perc_train * len(X_train)) # odd number\n",
    "                                     , random_state = 42\n",
    "                                     , verbose = 0 # no showing backend work\n",
    "                                     , n_jobs = -1 # access all of your processor cores Lenovo P50 i7-6820HQ 2.7GHz\n",
    "                                    )\n",
    "    elif symbol == 'JEF' and interval == '1d':\n",
    "        rfc = RandomForestClassifier(bootstrap = False\n",
    "                                     , max_depth = 2\n",
    "                                     , max_features = 2\n",
    "                                     , min_samples_leaf = 1\n",
    "                                     , min_samples_split = 2\n",
    "                                     , n_estimators = 45 # int(perc_train * len(X_train)) # odd number\n",
    "                                     , random_state = 42\n",
    "                                     , verbose = 0 # no showing backend work\n",
    "                                     , n_jobs = -1 # access all of your processor cores Lenovo P50 i7-6820HQ 2.7GHz\n",
    "                                    )\n",
    "    else:\n",
    "        rfc = RandomForestClassifier(bootstrap = True\n",
    "                                     , max_depth = 2\n",
    "                                     , max_features = 6\n",
    "                                     , min_samples_leaf = 3\n",
    "                                     , min_samples_split = 5\n",
    "                                     , n_estimators = 25 # int(perc_train * len(X_train)) # odd number\n",
    "                                     , random_state = 42\n",
    "                                     , verbose = 0 # no showing backend work\n",
    "                                     , n_jobs = -1 # access all of your processor cores Lenovo P50 i7-6820HQ 2.7GHz\n",
    "                                    )\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    y_probs = rfc.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # ROC Value\n",
    "    roc_value = roc_auc_score(y_test\n",
    "                              , y_probs\n",
    "                             )\n",
    "    \n",
    "    # AUC Score\n",
    "    rf_prec, rf_recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "    auc_value = round(auc(rf_recall, rf_prec), 3)\n",
    "    \n",
    "    # Feature Importances\n",
    "    # feature_df = pd.DataFrame({'feature': X_train.columns\n",
    "    #                            , 'importances': rfc.feature_importances_\n",
    "    #                           }\n",
    "    #                          ).sort_values('importances', ascending=False)\n",
    "    \n",
    "    # Current = 1 uses most up to date data, = 0 for one pervious current data\n",
    "    if current == 1:\n",
    "        loc = -1\n",
    "    else:\n",
    "        loc = loc\n",
    "        \n",
    "    # Prediction\n",
    "    last = stock_df[['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'percent change']].iloc[loc]\n",
    "    if rfc.predict(np.array(last).reshape(1, -1))[0] == 1:\n",
    "        result = f'Buy {symbol} on the {interval} interval for {round(perc_inc *100, 1)}% increase.'\n",
    "    else:\n",
    "        result = f'Sell or hold {symbol} on the {interval} interval.'\n",
    "        \n",
    "    return ones, roc_value, auc_value, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones, roc, auc, result = direction(interval = interval\n",
    "                                   , history = history\n",
    "                                   , perc_inc = perc_inc\n",
    "                                   , symbol = symbol\n",
    "                                   , perc_train = perc_train\n",
    "                                   , load_new = load_new \n",
    "                                   , current = current\n",
    "                                  )\n",
    "print(f'Positives: {ones}')\n",
    "print(f'ROC Score: {round(roc, 2)}')\n",
    "print(f'AUC Score: {round(auc, 2)}')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_df = pd.read_csv('stock_df.csv', index_col=index_col) # 'Date' for 1d, 'Datetime' for 60m\n",
    "stock_df['percent change'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_df['percent change'].quantile([0.84])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = [x*0.01 for x in range(5,105, 5)]\n",
    "perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_lst = []\n",
    "auc_lst = []\n",
    "results_lst = []\n",
    "perc = [x*0.01 for x in range(5,105, 5)]\n",
    "\n",
    "for x in perc:\n",
    "    ones, roc, auc, result = direction(interval = interval\n",
    "                                       , history = history\n",
    "                                       , perc_inc = perc_inc\n",
    "                                       , symbol = symbol\n",
    "                                       , perc_train = x\n",
    "                                       , load_new = load_new\n",
    "                                       , current = current\n",
    "                                      )\n",
    "    roc_lst.append(roc)\n",
    "    auc_lst.append(auc)\n",
    "    results_lst.append(result)\n",
    "\n",
    "results_df = pd.DataFrame({'Percent': perc\n",
    "                           , 'ROC': roc_lst\n",
    "                           , 'AUC': auc_lst\n",
    "                           , 'Result': results_lst\n",
    "                          }\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.Result.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(results_df.Percent\n",
    "            , results_df.ROC\n",
    "            , label = 'ROC'\n",
    "           )\n",
    "plt.scatter(results_df.Percent\n",
    "            , results_df.AUC\n",
    "            , label = 'AUC'\n",
    "           )\n",
    "plt.xlabel('Percent Train Estimators')\n",
    "plt.ylabel('Percent Score')\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.loc[results_df.ROC == results_df.ROC.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_perc = results_df.loc[results_df.ROC == results_df.ROC.max()].Percent.iloc[0]\n",
    "best_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones, roc, auc, result = direction(interval = interval\n",
    "                                   , history = history\n",
    "                                   , perc_inc = 0.02\n",
    "                                   , symbol = symbol\n",
    "                                   , perc_train = best_perc\n",
    "                                   , current = 1\n",
    "                                  )\n",
    "print(f'Positives: {ones}')\n",
    "print(f'ROC Score: {round(roc, 2)}')\n",
    "print(f'AUC Score: {round(auc, 2)}')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock_df.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twenty-One Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roc_scores = []\n",
    "auc_scores = []\n",
    "decisions = []\n",
    "for _ in range(21):\n",
    "    _, roc, auc, result = direction(interval = interval\n",
    "                                    , history = history\n",
    "                                    , perc_inc = perc_inc\n",
    "                                    , symbol = symbol\n",
    "                                    , perc_train = best_perc\n",
    "                                    , load_new = load_new\n",
    "                                    , current = current\n",
    "                                   )\n",
    "    roc_scores.append(roc)\n",
    "    auc_scores.append(auc)\n",
    "    decisions.append(result)\n",
    "\n",
    "twenty_one_df = pd.DataFrame({'roc': roc_scores\n",
    "                              , 'auc': auc_scores\n",
    "                              , 'decision': decisions\n",
    "                             })\n",
    "twenty_one_df.decision.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses and Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_df = pd.DataFrame({'Loss %': [0.01 * x for x in range(1,21,1)]\n",
    "                          , 'Needed Gain %': [1/(1-0.01*x)-1 for x in range(1,21,1)]\n",
    "                          , '% Difference': [(1/(1-0.01*x)-1-0.01*x)/(0.01*x)*100 for x in range(1,21,1)]\n",
    "                         }\n",
    "                        )\n",
    "losses_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
